Bird Model
==========

The bird model consists of three 1-D convolution layers, each with a kernel size of 3 and 30 channels. Each convolution layer is followed by batch normalization and a ReLU nonlinearity. The final projection layer is a linear layer that maps the average pooled embeddings to the number of classes. Cross-entropy loss is used as the classification loss. During training, dropout with a probability of 0.25 is applied after each convolution layer. The dataset for training consists of 3,505 labeled samples, each with 3 IMU accelerations and one GPS 2D speed for a sequence length of 20. There are 9 classes in total. AdamW is used for optimization with a learning rate of 3e-4 and a weight decay of 1e-2, with a maximum of 4,000 iterations. The learning rate scheduler is StepLR with a step size of 2,000, reducing the learning rate by a factor of 0.1. With this small dataset and model, the total training time is only 20 minutes using an NVIDIA GeForce RTX 3070 laptop GPU.